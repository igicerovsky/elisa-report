{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful code snippets for debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask multiindex table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import variation\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "def mask_sample_cv(df_in, valid_pts, cv_threshold):\n",
    "    df = df_in[df_in['mask'].isna()]\n",
    "    display(df)\n",
    "    cv_min = cv_threshold  # variation(df['concentration'], ddof=1)\n",
    "    non_mask_idx = []\n",
    "    indices = df.index\n",
    "    # Reverse combinations order to break if `CV` < `cv_threshold`\n",
    "    for l in reversed(range(2, len(indices) + 1)):\n",
    "        for subset in combinations(indices, l):\n",
    "            comb = list(subset)\n",
    "            t = df.loc[comb]\n",
    "            display(t)\n",
    "            cv = variation(t['concentration'], ddof=1)\n",
    "            print(comb, cv)\n",
    "            if cv < cv_min:\n",
    "                non_mask_idx = comb\n",
    "                cv_min = cv\n",
    "                print(f'!!! min {cv}')\n",
    "        # break if CV drops below threshold\n",
    "        if cv_min < cv_threshold:\n",
    "            break\n",
    "\n",
    "    mask_idx = list(set(indices).symmetric_difference(non_mask_idx))\n",
    "    return mask_idx, non_mask_idx, cv_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "idx = pd.MultiIndex.from_product([['A'],\n",
    "                                  [1, 2, 3, 4]],\n",
    "                                 names=['col', 'row'])\n",
    "col = ['concentration', 'mask']\n",
    "\n",
    "dfm = pd.DataFrame([(10, np.nan), (11, np.nan),\n",
    "                   (6, '<8'), (16, np.nan)], idx, col)\n",
    "display(dfm)\n",
    "\n",
    "# display(dfm['mask'].isna())\n",
    "m_idx, _, _ = mask_sample_cv(dfm, 2, 0.2)\n",
    "display(m_idx)\n",
    "dfm.loc[m_idx, ['mask']] = \"cv-masked\"\n",
    "display(dfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report dir handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def listdirs(rootdir):\n",
    "    dirs = []\n",
    "    for it in os.scandir(rootdir):\n",
    "        if it.is_dir():\n",
    "            dirs.append(it.path)\n",
    "            # print(it.path)\n",
    "    return dirs\n",
    "\n",
    "\n",
    "rootdir = './../reports/all/'\n",
    "dirs = listdirs(rootdir)\n",
    "dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dir_name(path_name):\n",
    "    if os.path.isdir(path_name):\n",
    "        path_name = os.path.basename(path_name)\n",
    "    else:\n",
    "        raise Exception('Not directory!')\n",
    "    s = path_name.split('_')\n",
    "    dc = {'date': s[0], 'protocol': s[1], 'analyst': s[2], 'gn': s[3]}\n",
    "    return dc\n",
    "\n",
    "def make_base_name(date, gn):\n",
    "    return date + '_' + gn + '_-_'\n",
    "\n",
    "for work_dir in dirs:\n",
    "    p = parse_dir_name(work_dir)\n",
    "    print(p)\n",
    "    b = make_base_name(p['date'], p['gn'])\n",
    "    print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "def make_input_paths(input_dir):\n",
    "    print(input_dir)\n",
    "    p =  parse_dir_name(input_dir)\n",
    "    print(p)\n",
    "    base_name = make_base_name(p['date'], p['gn'])\n",
    "    worklist = path.join(input_dir, base_name + 'worklist-ELISA.xls')\n",
    "    if not path.isfile(worklist):\n",
    "        raise Exception(\"Worklist file path is invlaid: {}\".format(worklist))\n",
    "\n",
    "    params = path.join(input_dir, base_name + p['protocol'] +'_Parameters.csv')\n",
    "    if not path.isfile(params):\n",
    "        raise Exception(\"Parameters file path is invlaid: {}\".format(params))\n",
    "\n",
    "    return {'worklist': worklist, 'params': params}\n",
    "\n",
    "make_input_paths(dirs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing / checking worklist and params path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def parse_file_path(path_name):\n",
    "    if not os.path.isfile(path_name):\n",
    "        raise Exception('Not directory!')\n",
    "    fl = os.path.split(path_name)\n",
    "    s = fl[1].split('_')\n",
    "    dc = { 'dir': fl[0], 'file': fl[1], 'date': s[0], 'gn': s[1], 'analyst': s[2], 'protocol': s[3]}\n",
    "    return dc\n",
    "\n",
    "# params_path = 'c:/work/report-gen/reports/all/230530_AAV9-ELISA_sey_GN004240-040/230530_GN004240-040_-_AAV9-ELISA_Parameters.csv'\n",
    "params_path = './../reports/all/230530_AAV9-ELISA_sey_GN004240-040/230530_GN004240-040_-_AAV9-ELISA_Parameters.csv'\n",
    "# worklist_path = 'c:/work/report-gen/reports/all/230530_AAV9-ELISA_sey_GN004240-040/230530_GN004240-040_-_worklist-ELISA.xls'\n",
    "worklist_path = './../reports/all/230530_AAV9-ELISA_sey_GN004240-040/230530_GN004240-040_-_worklist-ELISA.xls'\n",
    "\n",
    "htp = os.path.split(params_path)\n",
    "# print('params path split {} / {}'.format(htp[0], htp[1]))\n",
    "pp = parse_file_path(params_path)\n",
    "print(pp)\n",
    "\n",
    "htw = os.path.split(worklist_path)\n",
    "# print('worklist path split {} / {}'.format(htw[0], htw[1]))\n",
    "pw = parse_file_path(worklist_path)\n",
    "print(pw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date, time, timezone\n",
    "\n",
    "dt = datetime.strptime(\"21/11/06 16:30\", \"%d/%m/%y %H:%M\")\n",
    "dt = datetime.strptime('230530', \"%y%m%d\")\n",
    "print(dt.strftime('%d %b %Y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read params from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from os import path\n",
    "\n",
    "working_dir = './../reports/230426_AAV9-ELISA_igi_GN004240-033'\n",
    "params_path_default = path.join('./../data', 'params.json')\n",
    "params_path_local = path.join(working_dir, 'params.json')\n",
    "params_path = None\n",
    "\n",
    "if path.exists(params_path_local):\n",
    "    params_path = params_path_local\n",
    "    print(f'loading local params {params_path}')\n",
    "elif path.exists(params_path_default):\n",
    "    params_path = params_path_default\n",
    "    print(f'loading default params {params_path}')\n",
    "\n",
    "\n",
    "with open(params_path_default) as json_file:\n",
    "    data = json.load(json_file)\n",
    "    dilutions = data['dilutions']\n",
    "    ref_val_max = data['referenceValue']\n",
    "\n",
    "print(f'{ref_val_max}, {dilutions}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert parameters CSV to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "scv_filepath = './../reports/230426_AAV9-ELISA_igi_GN004240-033/230426_GN004240-033_-_AAV9-ELISA_Parameters.csv'\n",
    "df = pd.read_csv(scv_filepath, sep=';', index_col='Variable', header=0)\n",
    "# df = pd.read_csv(scv_filepath, sep=';', index_col=False)\n",
    "display(df)\n",
    "# json_filepath = path.splitext(scv_filepath)[0] + '.json'\n",
    "# df.to_json(json_filepath, indent=4, orient=\"columns\", force_ascii=False)\n",
    "# df.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(df.loc['IncubationTime_Samples', :].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "parameters_path = './../reports/230426_AAV9-ELISA_igi_GN004240-033/230426_GN004240-033_-_AAV9-ELISA_Parameters.json'\n",
    "with open(parameters_path) as json_file:\n",
    "    p = json.load(json_file)\n",
    "\n",
    "p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
