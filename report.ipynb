{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VzMkIHAq87Dq"
      },
      "source": [
        "# Intro"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Goal\n",
        "**WHAT**: Automatic report generation from Hamilton measurements.  \n",
        "**WHY**: Speed up the report generation, and avoid human errors (copying data, subjective evaluation, ....)\n",
        "\n",
        "## Tools\n",
        "Fast iteration in an agile way.  \n",
        "Generic approach - different plates setup, prameters, ... all with the same code, no changes needed.  \n",
        "\n",
        "**Python** programming language.  \n",
        "**jupyter** notebook is currently used, with some functions divided into small modules.  \n",
        "**Visual Studio Code** IDE (Integrated Development Environment).  \n",
        "**Markdown** (*.md) format for generated report (Simple, humanly redable).  \n",
        "\n",
        "## Input:\n",
        " - Worklist file path (*.xls) as used for Hamilton input.\n",
        "   - Sample name\n",
        "   - Dilution\n",
        "   - Viscosity\n",
        " - Measurement results file path (*.xls) as output from Hamilton.\n",
        " - Parameters; constants in code (file path *.json)\n",
        "   - CV (Coefficient of variation) threshold\n",
        "   - Referennce value (1.7954e+10 cp/ml)\n",
        "   - Dilutions [1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0]\n",
        "   - Decimal digits for output\n",
        "\n",
        "## Output:\n",
        "  - Report (*.md, printable to pdf)\n",
        "    - Could be manually edited\n",
        "    - Image files\n",
        "    - Result sheets\n",
        "  - Estimated size <2kB (current)\n",
        "\n",
        "## Done\n",
        "  - Invalid sample:\n",
        "    - CV >THRESHOLD\n",
        "    - Only one point\n",
        "  - Parameters file (*.scv, *.json)\n",
        "  - Multiple plates (in worklist file)\n",
        "  - Modules\n",
        "  - Running modes\n",
        "    - Python script - automatic run (command line with parameters)\n",
        "\n",
        "## TODO:\n",
        "  - Finalize the report\n",
        "    - 2 decimal places\n",
        "  - Running modes\n",
        "    - GUI; use modules to crete an App (code remains the same, but used from GUI)\n",
        "  - Tests (unit, integration)\n",
        "  - checksum (*.sdax); put into report\n",
        "  - Extensive testing...\n",
        "  - Automatic print to *.pdf ?\n",
        "  - md2pdf\n",
        "\n",
        "## Conclusion\n",
        "End to end evaluation time reduction approximately 2h -> 20min per measurement. (thx Felix)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generate report  - POC\n",
        "\n",
        "[AV9 data folder](<../../Users/hwn6193/OneDrive - Takeda/General - Gene Therapy Analytics (AD+PA)/3_Teams/3.1_Protein_Quantification/_AAV9 Capsid ELISA>)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Review bugs\n",
        "### TODO\n",
        "\n",
        "### Fixed\n",
        "- mask sample point(s) if `CV>CV_THRESHOLD` and `valid sample_poitns <= MIN_VALID_SAMPLE_POINTS` (Igor)\n",
        "- `CV[%]` one `{:.1f}` decimal digit (Felix)\n",
        "- `Result [cp/ml]` three `{:.3e}` (Felix)\n",
        "- `nan` -> `NA` (Felix)\n",
        "- control sample image line ending (Sebastian)\n",
        "- `CV[%]` column format to 2 decimal digits with trailing zeroes (Sebastian/Robert)\n",
        "- Fit parameter description https://teams.microsoft.com/l/message/19:4ba886dcae16442f802adcc65edc04bb@thread.v2/1688557386620?context=%7B%22contextType%22%3A%22chat%22%7D (Felix)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "VERBOSE_NOTEBOOK = False\n",
        "WARNING_DISABLE = True\n",
        "DEBUG = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DScHnqGC95-6"
      },
      "outputs": [],
      "source": [
        "from os import path\n",
        "import warnings\n",
        "from scipy.optimize import OptimizeWarning\n",
        "\n",
        "if WARNING_DISABLE:\n",
        "    warnings.simplefilter('ignore', RuntimeWarning)\n",
        "    warnings.simplefilter('ignore', OptimizeWarning)\n",
        "    warnings.filterwarnings('ignore', category=UserWarning, module='openpyxl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from mkinout import make_input_paths\n",
        "WORKING_DIR = './reports/input/'\n",
        "BASE_NAME = '230426_GN004240-033_-_'\n",
        "\n",
        "# WORKING_DIR = './reports/all/230628_AAV9-ELISA_sey_GN004240-046'\n",
        "# BASE_NAME = '230628_GN004240-046_-_'\n",
        "\n",
        "input_files = make_input_paths(WORKING_DIR, BASE_NAME)\n",
        "WORKLIST_FILE_PATH = input_files['worklist']\n",
        "PARAMS_FILE_PATH = input_files['params']\n",
        "\n",
        "DATA_DIR = './data'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BNLvIjir8ygz"
      },
      "source": [
        "## Layouts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "EhcUq4gagUvF",
        "outputId": "419c96ca-d9f1-4c13-f3f8-ad9e23662719"
      },
      "outputs": [],
      "source": [
        "from readdata import read_layouts\n",
        "\n",
        "PLATE_LAYOUT_ID = 'plate_layout_ident.csv'\n",
        "PLATE_LAYOUT_NUM = 'plate_layout_num.csv'\n",
        "PLATE_LAYOUT_DIL_ID = 'plate_layout_dil_id.csv'\n",
        "\n",
        "\n",
        "g_lay = read_layouts(path.join(DATA_DIR, PLATE_LAYOUT_ID),\n",
        "                     path.join(DATA_DIR, PLATE_LAYOUT_NUM),\n",
        "                     path.join(DATA_DIR, PLATE_LAYOUT_DIL_ID))\n",
        "\n",
        "if VERBOSE_NOTEBOOK:\n",
        "    display(g_lay)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Worklist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from worklist import read_worklist, check_worklist\n",
        "from readdata import read_params\n",
        "\n",
        "g_wl_raw = read_worklist(WORKLIST_FILE_PATH)\n",
        "g_valid_plates = check_worklist(g_wl_raw)\n",
        "g_params = read_params(PARAMS_FILE_PATH)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dilution to Concentration\n",
        "\n",
        "Define dilution dataframe. The dataframe is indexed according plate layout, index of refference dataframe corresponds to refference of the `plate_layout_dil`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: read reference value from parameters\n",
        "REF_VAL_MAX = 1.7954e+10\n",
        "DILUTIONS = [1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0]\n",
        "\n",
        "from sample import make_concentration\n",
        "g_reference_conc = make_concentration(REF_VAL_MAX, DILUTIONS)\n",
        "\n",
        "if VERBOSE_NOTEBOOK:\n",
        "    display(g_reference_conc)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Report generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from reportmain import report_plate, check_report_crc\n",
        "from mkinout import make_output_paths\n",
        "\n",
        "def gen_report(valid_plates, worklist, params, layout, reference_conc,\n",
        "               working_dir, base_name):\n",
        "    reports = []\n",
        "    for plate in valid_plates:\n",
        "        print('Processing plate {} of {}'.format(plate, len(valid_plates)))\n",
        "\n",
        "        output_files = make_output_paths(working_dir, base_name, plate)\n",
        "        result_file_path = output_files['results']\n",
        "        report_file_path = output_files['report']\n",
        "        report_dir = path.dirname(path.abspath(report_file_path))\n",
        "        reports.append(report_plate(plate, worklist, params, layout,\n",
        "                    reference_conc, result_file_path, report_dir, report_file_path\n",
        "                    ))\n",
        "    return reports\n",
        "\n",
        "\n",
        "reports = gen_report(g_valid_plates, g_wl_raw, g_params, g_lay, g_reference_conc, WORKING_DIR, BASE_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CHECK_REPORT_CRC = True\n",
        "REPORT_PLATES_CRC = [985937237, 3856888741]\n",
        "if CHECK_REPORT_CRC:\n",
        "    for report, crc in zip(reports, REPORT_PLATES_CRC):\n",
        "        check_report_crc(report, crc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use pandoc to convert markdown to Word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ! c:/work/pandoc/pandoc -o output.docx -f markdown -t docx {reports[0]}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DEBUG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "  \n",
        "# Initialize data to Dicts of series.\n",
        "d = {'concentration': pd.Series([10, 11, 7, 14],\n",
        "                      index=[0, 1, 2, 3]),\n",
        "    'mask': pd.Series([np.nan, np.nan, '<8', np.nan],\n",
        "                      index=[0, 1, 2, 3])}\n",
        "  \n",
        "# creates Dataframe.\n",
        "dfd = pd.DataFrame(d)\n",
        "  \n",
        "# print the data.\n",
        "dfd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.stats import variation\n",
        "from itertools import combinations\n",
        "\n",
        "def mask_sample_cv(df_in, valid_pts, cv_threshold):\n",
        "    df = df_in[df_in['mask'].isna()]\n",
        "    display(df)\n",
        "    cv_min = cv_threshold # variation(df['concentration'], ddof=1)\n",
        "    non_mask_idx = []\n",
        "    indices = df.index\n",
        "    # Reverse combinations order to break if `CV` < `cv_threshold`\n",
        "    for l in reversed(range(2, len(indices) + 1)):\n",
        "        for subset in combinations(indices, l):\n",
        "            comb = list(subset)\n",
        "            t = df.loc[comb]\n",
        "            display(t)\n",
        "            cv = variation(t['concentration'], ddof=1)\n",
        "            print(comb, cv)\n",
        "            if cv < cv_min:\n",
        "                non_mask_idx = comb\n",
        "                cv_min = cv\n",
        "                print(f'!!! min {cv}')\n",
        "        # break if CV drops below threshold\n",
        "        if cv_min < cv_threshold:\n",
        "            break\n",
        "\n",
        "    mask_idx = list(set(indices).symmetric_difference(non_mask_idx))\n",
        "    return mask_idx, non_mask_idx, cv_min\n",
        "\n",
        "display(dfd['mask'].isna())\n",
        "m_idx,_,_ = mask_sample_cv(dfd, 2, 0.2)\n",
        "display(m_idx)\n",
        "dfd.loc[m_idx, ['mask']] = \"cv-masked\"\n",
        "display(dfd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "idx = pd.MultiIndex.from_product([['A'],\n",
        "                                  [1, 2, 3, 4]],\n",
        "                                 names=['col', 'row'])\n",
        "col = ['concentration', 'mask']\n",
        "\n",
        "dfm = pd.DataFrame([(10,np.nan) ,(11,np.nan),(6,'<8'),(16,np.nan)], idx, col)\n",
        "display(dfm)\n",
        "\n",
        "# display(dfm['mask'].isna())\n",
        "m_idx,_,_ = mask_sample_cv(dfm, 2, 0.2)\n",
        "display(m_idx)\n",
        "dfm.loc[m_idx, ['mask']] = \"cv-masked\"\n",
        "display(dfm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DIGITS = 3\n",
        "'{0} {1:.{dgts}e}'.format(DIGITS, 1.234572, dgts=DIGITS)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
