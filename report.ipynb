{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VzMkIHAq87Dq"
      },
      "source": [
        "# Intro"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Goal\n",
        "**WHAT**: Automatic report generation from Hamilton measurements.  \n",
        "**WHY**: Speed up the report generation, and avoid human errors (copying data, subjective evaluation, ....)\n",
        "\n",
        "## Tools\n",
        "Fast iteration in an agile way.  \n",
        "Generic approach - different plates setup, prameters, ... all with the same code, no changes needed.  \n",
        "\n",
        "**Python** programming language.  \n",
        "**jupyter** notebook is currently used, with some functions divided into small modules.  \n",
        "**Visual Studio Code** IDE (Integrated Development Environment).  \n",
        "**Markdown** (*.md) format for generated report (Simple, humanly redable).  \n",
        "\n",
        "## Input:\n",
        " - Worklist file path (*.xls) as used for Hamilton input.\n",
        "   - Sample name\n",
        "   - Dilution\n",
        "   - Viscosity\n",
        " - Measurement results file path (*.xls) as output from Hamilton.\n",
        " - Parameters; constants in code (file path *.json)\n",
        "   - CV (Coefficient of variation) threshold\n",
        "   - Referennce value (1.7954e+10 cp/ml)\n",
        "   - Dilutions [1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0]\n",
        "   - Decimal digits for output\n",
        "\n",
        "## Output:\n",
        "  - Report (*.md, printable to pdf)\n",
        "    - Could be manually edited\n",
        "    - Image files\n",
        "    - Result sheets\n",
        "  - Estimated size <2kB (current)\n",
        "\n",
        "## Done\n",
        "  - Invalid sample:\n",
        "    - CV >THRESHOLD\n",
        "    - Only one point\n",
        "  - Parameters file (*.scv, *.json)\n",
        "  - Multiple plates (in worklist file)\n",
        "\n",
        "## TODO:\n",
        "  - Modules\n",
        "  - Finalize the report\n",
        "  - Running modes\n",
        "    - Python script - automatic run (command line with parameters)\n",
        "    - GUI; use modules to crete an App (code remains the same, but used from GUI)\n",
        "  - Tests (unit, integration)\n",
        "  - checksum (*.sdax); put into report\n",
        "  - Extensive testing...\n",
        "  - Automatic print to *.pdf ?\n",
        "\n",
        "## Conclusion\n",
        "End to end evaluation time reduction approximately 2h -> 20min per measurement. (thx Felix)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generate report  - POC"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "VERBOSE_NOTEBOOK = True\n",
        "WARNING_DISABLE = True\n",
        "DEBUG = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DScHnqGC95-6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from os import path\n",
        "import os\n",
        "import constants as cc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_input_paths(input_dir, base_name):\n",
        "    worklist = path.join(input_dir, base_name + 'worklist-ELISA.xls')\n",
        "    if not os.path.isfile(worklist):\n",
        "        raise Exception(\"Worklist file path is invlaid: {}\".format(worklist))\n",
        "\n",
        "    params = path.join(input_dir, base_name + 'AAV9-ELISA_Parameters.csv')\n",
        "\n",
        "    return {'worklist': worklist, 'params': params}\n",
        "\n",
        "def make_output_paths(input_dir, base_name, sample_num):\n",
        "    results =  path.join(input_dir, base_name + 'calc{}.xlsx'.format(sample_num))\n",
        "    if not os.path.isfile(results):\n",
        "        raise Exception(\"Rewsults file path is invlaid: {}\".format(results))\n",
        "    \n",
        "    report = path.join(input_dir, 'results_{}'.format(sample_num))\n",
        "    report = path.join(report, '{}report_{}.md'.format(base_name, sample_num))\n",
        "\n",
        "    return {'results': results, 'report': report}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "WORKING_DIR = './data/input/'\n",
        "BASE_NAME = '230426_GN004240-033_-_'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zV2iKp5f9-Ui"
      },
      "source": [
        "## Read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "9QyeTtP3gQN0",
        "outputId": "f07cb86c-f322-432b-abb5-f785f8efd4be"
      },
      "outputs": [],
      "source": [
        "PLATE_ID = 1 # plate id\n",
        "\n",
        "input_files = make_input_paths(WORKING_DIR, BASE_NAME)\n",
        "WORKLIST_FILE_PATH = input_files['worklist']\n",
        "PARAMS_FILE_PATH = input_files['params']\n",
        "\n",
        "output_files = make_output_paths(WORKING_DIR, BASE_NAME, PLATE_ID)\n",
        "RESULT_FILE_PATH = output_files['results']\n",
        "REPORT_FILE_PATH = output_files['report']\n",
        "REPORT_DIR = os.path.dirname(os.path.abspath(REPORT_FILE_PATH))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "xoHKHdi6pVOp",
        "outputId": "25c35044-7f6c-405a-e516-cfd8c631a2cb"
      },
      "outputs": [],
      "source": [
        "from readdata import read_concat_data\n",
        "\n",
        "g_od = read_concat_data(RESULT_FILE_PATH)\n",
        "display(g_od)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BNLvIjir8ygz"
      },
      "source": [
        "### Layouts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "EhcUq4gagUvF",
        "outputId": "419c96ca-d9f1-4c13-f3f8-ad9e23662719"
      },
      "outputs": [],
      "source": [
        "from layouthandle import read_plate_layout\n",
        "\n",
        "g_plate_layout_id = read_plate_layout('./data/plate_layout_ident.csv')\n",
        "g_plate_layout_num = read_plate_layout('./data/plate_layout_num.csv')\n",
        "g_plate_layout_dil_id = read_plate_layout('./data/plate_layout_dil_id.csv')\n",
        "\n",
        "if VERBOSE_NOTEBOOK:\n",
        "    display(g_plate_layout_id)\n",
        "    display(g_plate_layout_num)\n",
        "    display(g_plate_layout_dil_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from readdata import concat_data_with_layouts\n",
        "\n",
        "df_all = concat_data_with_layouts(g_od, g_plate_layout_id, g_plate_layout_num, g_plate_layout_dil_id)\n",
        "\n",
        "if VERBOSE_NOTEBOOK:\n",
        "    display(g_od)\n",
        "    display(df_all)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dilution to Concentration\n",
        "\n",
        "Define dilution dataframe. The dataframe is indexed according plate layout, index of refference dataframe corresponds to refference of the `plate_layout_dil`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: read reference value from parameters\n",
        "REF_VAL_MAX = 1.7954e+10\n",
        "DILUTIONS = [1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0]\n",
        "\n",
        "from sample import make_concentration\n",
        "g_reference_conc = make_concentration(REF_VAL_MAX, DILUTIONS)\n",
        "\n",
        "if VERBOSE_NOTEBOOK:\n",
        "    display(g_reference_conc)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "from scipy.optimize import OptimizeWarning\n",
        "\n",
        "if WARNING_DISABLE:\n",
        "    warnings.simplefilter('ignore', RuntimeWarning)\n",
        "    warnings.simplefilter('ignore', OptimizeWarning)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get the fitting data from dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "g_ref = df_all.loc[(df_all['plate_layout_ident']=='r')].copy()\n",
        "g_ref['plate_layout_conc'] = g_ref['plate_layout_dil_id'].map(g_reference_conc['concentration'])\n",
        "if VERBOSE_NOTEBOOK:\n",
        "    display(g_ref)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit with confidence interval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from image import fit_image\n",
        "from fitdata import fit_reference_auto_rm\n",
        "\n",
        "x = g_ref.reset_index(level=[0,1])['plate_layout_conc']\n",
        "y = g_ref.reset_index(level=[0,1])['OD_delta']\n",
        "g_fit = fit_reference_auto_rm(x, y, verbose=False)\n",
        "g_popt = g_fit[0][0]\n",
        "g_pcov = g_fit[0][1]\n",
        "\n",
        "fit_image(x, y, g_fit[0][0], g_fit[0][1], None, confidence='student-t', rm_index=g_fit[1])\n",
        "display(g_fit[3])\n",
        "display(g_fit[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sample import data_range\n",
        "\n",
        "g_dr = data_range(g_ref, g_popt)\n",
        "\n",
        "if VERBOSE_NOTEBOOK:\n",
        "    print('Concentration backfit [cp/ml] range <{0}, {1}>'.format(g_dr.cb[0], g_dr.cb[1]))\n",
        "    print('Standard Value [cp/ml] range <{0}, {1}>'.format(g_dr.sv[0], g_dr.sv[1]))\n",
        "    print('SV to OD fit range <{0:.4f}, {1:.4f}>'.format(g_dr.od_fit[0], g_dr.od_fit[1]))\n",
        "    print('Optical density range <{0:.4f}, {1:.4f}>'.format(g_dr.od[0], g_dr.od[1]))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sample evaluation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compute concentration for all `s` and `k` samples\n",
        "\n",
        "Fit the data, and apply the inverse function as a check..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sample import init_samples\n",
        "from sample import apply_fit\n",
        "from sample import mask_sample\n",
        "from sample import generate_results\n",
        "from image import fit_image\n",
        "from fitdata import fit_reference_auto_rm\n",
        "from fitdata import backfit\n",
        "from sample import data_range\n",
        "\n",
        "dfg = init_samples(df_all, g_reference_conc)\n",
        "\n",
        "\n",
        "# g_ref = dfg.loc[(dfg['plate_layout_ident']=='r')].copy()\n",
        "# display(g_ref)\n",
        "# x = g_ref.reset_index(level=[0,1])['plate_layout_conc']\n",
        "# y = g_ref.reset_index(level=[0,1])['OD_delta']\n",
        "# g_fit = fit_reference_auto_rm(x, y, verbose=False)\n",
        "# g_popt = g_fit[0][0]\n",
        "# g_pcov = g_fit[0][1]\n",
        "\n",
        "# fit_image(x, y, g_fit[0][0], g_fit[0][1], None, confidence='student-t', rm_index=g_fit[1])\n",
        "# display(g_fit[3])\n",
        "# display(g_fit[1])\n",
        "\n",
        "# g_dr = data_range(g_ref, g_popt)\n",
        "\n",
        "dfg = apply_fit(dfg, g_popt)\n",
        "sadfgmplesk = mask_sample(dfg, g_dr)\n",
        "sl = generate_results(dfg, g_dr)\n",
        "\n",
        "samplesk = dfg\n",
        "\n",
        "if VERBOSE_NOTEBOOK:\n",
        "    display(samplesk)\n",
        "    display(sl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if VERBOSE_NOTEBOOK:\n",
        "    print('Concentration backfit [cp/ml] range <{0}, {1}>'.format(g_dr.cb[0], g_dr.cb[1]))\n",
        "    print('Standard Value [cp/ml] range <{0}, {1}>'.format(g_dr.sv[0], g_dr.sv[1]))\n",
        "    print('SV to OD fit range <{0:.4f}, {1:.4f}>'.format(g_dr.od_fit[0], g_dr.od_fit[1]))\n",
        "    print('Optical density range <{0:.4f}, {1:.4f}>'.format(g_dr.od[0], g_dr.od[1]))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot sample with referene curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from image import sample_img\n",
        "\n",
        "if VERBOSE_NOTEBOOK:\n",
        "    sample_img(samplesk, g_ref, 's', 6)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Worklist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sample import final_sample_info\n",
        "import worklist as wk\n",
        "\n",
        "g_wl_raw = wk.read_worklist(WORKLIST_FILE_PATH)\n",
        "g_valid_plates = wk.check_worklist(g_wl_raw)\n",
        "\n",
        "# TODO: nasty, using globals!!!\n",
        "def make_final(wl_raw, plate_id):\n",
        "    wl, wl_cols_dict = wk.worklist_sample(wl_raw, plate_id)\n",
        "\n",
        "    final = pd.concat([wl, sl], axis=1)\n",
        "    cd = wl_cols_dict\n",
        "    final.loc[:, ['Result [cp/ml]']] = final.apply(lambda x: x['Reader Data [cp/ml]'] * x[cd['Dilution']], axis=1)\n",
        "    final.loc[:, ['CV [%]']] = final.apply(lambda x: x['CV [%]'] * 100, axis=1)\n",
        "    # reorder columns\n",
        "    final = final.reindex([cd['SampleID'], cd['Dilution'], cd['Viscosity'], 'Reader Data [cp/ml]', 'Result [cp/ml]', 'CV [%]', 'Valid', 'info'], axis=1)\n",
        "    final.rename(columns={cd['SampleID']: 'Sample Name', cd['Dilution']: 'Pre-dilution'}, inplace=True)\n",
        "    final.drop('Viscosity_{}'.format(plate_id), axis=1, inplace=True)\n",
        "    final.index.name = 'Sample type'\n",
        "    final.loc[:, ['info_ex']] = final.apply(lambda x: final_sample_info(x['info'], x['Pre-dilution'])[0], axis=1)\n",
        "    final.loc[:, ['valid_ex']] = final.apply(lambda x: final_sample_info(x['info'], x['Pre-dilution'])[1], axis=1)\n",
        "    return final"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gZvoKky5-zeC"
      },
      "source": [
        "## Report  \n",
        "We build a report here..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fit Reference Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from fitdata import fit_sheet\n",
        "\n",
        "def fit_section_md(df_ref, popt, pcov, out_dir):\n",
        "    x = df_ref.reset_index(level=[0,1])['plate_layout_conc']\n",
        "    y = df_ref.reset_index(level=[0,1])['OD_delta']\n",
        "    fit_result = fit_reference_auto_rm(x, y)\n",
        "    result_img = path.join(out_dir, 'fit.svg')\n",
        "    fit_image(x, y, fit_result[0][0], fit_result[0][1], result_img,\n",
        "      confidence='student-t', rm_index=fit_result[1], verbose=False, show=False)\n",
        " \n",
        "    n = len(x) - len(fit_result[1])\n",
        "    df_fit = fit_sheet(popt, pcov, n)\n",
        "\n",
        "    md = '## Reference Curve Fit\\n\\n'\n",
        "    md += '$\\LARGE y = {d + {a - d \\over {1 + ({ x \\over c })^b}} }$  \\n\\n'\n",
        "    md += '![\"alt text\"](./img/fit.svg)'\n",
        "\n",
        "    md += '\\n\\n'\n",
        "    md += 'Verbose fitting progress, metric is R-squared:\\n\\n'\n",
        "    md += fit_result[3].to_markdown() + '\\n\\n'\n",
        "\n",
        "    md += 'Fit parameters\\n\\n'\n",
        "    md += df_fit.to_markdown(index=False) + '\\n\\n'\n",
        "    md += 'Backfit...'\n",
        "    fit_result = fit_reference_auto_rm(x, y)\n",
        "    df_backfit = backfit(df_ref, fit_result[0][0])\n",
        "    md += '\\n\\n' + df_backfit.to_markdown() + '\\n\\n'\n",
        "\n",
        "    return md"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mITvKNH5-4fX"
      },
      "source": [
        "### Sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRtUZG23mF2m"
      },
      "outputs": [],
      "source": [
        "from sample import sampleinfo_to_str\n",
        "from sample import sample_check\n",
        "from sample import sample_info\n",
        "\n",
        "def sample_to_md(dc):\n",
        "    s_view = dc['sample'][['OD_delta', 'plate_layout_dil', 'concentration', 'mask_reason']]\n",
        "    md = \"### Sample: {0} '{1}' {2}\\n\\n\".format(cc.SAMPLE_TYPES[dc['type']], dc['type'], dc['num'])\n",
        "    md += s_view.to_markdown()\n",
        "    md += '\\n\\n'\n",
        "    md += \"CV = {:2.3} [%]  \\n\".format(100 * dc['cv'])\n",
        "    md += \"mean = {:.4} [cp/ml]  \\n\".format(dc['mean'])\n",
        "    md += \"valid = {}  \\n\".format(dc['valid'])\n",
        "    if dc['note']:\n",
        "         md += \"note: {}  \".format(dc['note'])\n",
        "\n",
        "    return md\n",
        "\n",
        "def sample_section_md(samples, reference, img_dir):\n",
        "    md = '## Sample evaluation\\n\\n' \n",
        "    k = sample_check(samples, 'k', 1)\n",
        "    md += sample_to_md(k)\n",
        "    sfile = 'control_{0:02d}.svg'.format(1)\n",
        "    img_file = path.join(img_dir, sfile)\n",
        "    sample_img(samples, reference, 'k', 1, img_file, show=False)\n",
        "    md += '![\"alt text\"](./img/{})\\n\\n'.format(sfile)\n",
        "    sample_n = samples['plate_layout_num'].astype(int).unique()\n",
        "    sample_n.sort()\n",
        "    for i in sample_n:\n",
        "        stype = 's'\n",
        "        s = sample_check(samples, stype, i)\n",
        "        md += sample_to_md(s)\n",
        "        # sample info\n",
        "        si = sample_info(samples, stype, i, g_dr, verbose=False)\n",
        "        si_str = sampleinfo_to_str(si['info'])\n",
        "        if si_str:\n",
        "            md += '\\n'\n",
        "            md += 'info: ' + si_str + '  '\n",
        "        md += '\\n'\n",
        "        sfile = 'sample_{0:02d}.svg'.format(i)\n",
        "        img_file = path.join(img_dir, sfile)\n",
        "        sample_img(samples, reference, stype, i, img_file=img_file, show=False, verbose=False)\n",
        "        md += '![{0}](./img/{0})\\n\\n'.format(sfile)\n",
        "    return md\n",
        "\n",
        "def save_md(file_path, md_txt):\n",
        "    try:\n",
        "        with open(file_path, 'w') as fl:\n",
        "            fl.write(md_txt)\n",
        "    except Exception as e:\n",
        "        print('Error: ' + str(e))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sample import final_sample_info\n",
        "import math\n",
        "\n",
        "final_result = make_final(g_wl_raw, PLATE_ID)\n",
        "\n",
        "def format_resluts_val(x):\n",
        "    res = ''\n",
        "    if math.isnan(x['Result [cp/ml]']):\n",
        "        res = x['Comment']\n",
        "    else:\n",
        "        res = '{:.4e}'.format(x['Result [cp/ml]'])\n",
        "    if x['valid_ex']:\n",
        "        res = '**{}**'.format(res)\n",
        "    else:\n",
        "        res = '( {} )*'.format(res)\n",
        "    \n",
        "    return res\n",
        "\n",
        "def format_results(df):\n",
        "    df.loc[:, ['Comment']] = df.apply(lambda x: final_sample_info(x['info'], x['Pre-dilution'])[0], axis=1)\n",
        "    df.loc[:, ['CV [%]']] = df.apply(lambda x:'{:.2f}'.format(x['CV [%]']), axis=1)\n",
        "    # df.loc[:, ['Result [cp/ml]']] = df.apply(lambda x: x['Comment'] if math.isnan(x['Result [cp/ml]']) else '{:.4e}'.format(x['Result [cp/ml]']), axis=1)\n",
        "    # display(df)\n",
        "    df.loc[:, ['Result [cp/ml]']] = df.apply(lambda x: format_resluts_val(x), axis=1)\n",
        "    df.drop(['info', 'Valid', 'Reader Data [cp/ml]', 'info_ex', 'valid_ex'], axis=1, inplace=True)\n",
        "    \n",
        "    return df\n",
        "\n",
        "def result_section(df):\n",
        "    md = '## Analysis Results\\n\\n'\n",
        "\n",
        "    md += format_results(df).to_markdown()\n",
        "    md += '\\n\\n'\n",
        "    md += '\\* sample will be retested\\n\\n'\n",
        "    \n",
        "    return md"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Header"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def header_section(date, id, plate_id, msg):\n",
        "    md =  '## Header\\n\\n'\n",
        "\n",
        "    md += 'Date: {}\\n\\n'.format(date)\n",
        "    md += 'Identification: {}\\n\\n'.format(id)\n",
        "    md += 'Plate: {}\\n\\n'.format(plate_id)\n",
        "    md += 'Comment: {}\\n\\n'.format(msg)\n",
        "\n",
        "    return md;"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def param_section(df_params):\n",
        "    md =  '## Parameters\\n\\n'\n",
        "\n",
        "    md += 'Parameters:\\n\\n' + df_params.to_markdown() + '\\n\\n'\n",
        "\n",
        "    return md;\n",
        "\n",
        "if VERBOSE_NOTEBOOK:\n",
        "    final_result"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Report Assembly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from readdata import read_params\n",
        "from zlib import crc32\n",
        "\n",
        "params = read_params(PARAMS_FILE_PATH)\n",
        "\n",
        "report = '''\n",
        "# Automatically Generated Markdown report\n",
        "\n",
        "This a PoC for automatic report generation...  \n",
        "\n",
        "'''\n",
        "\n",
        "report += header_section('05 May 2023', 'GN004240-033', PLATE_ID, ':)')\n",
        "report += result_section(final_result.drop('reference 01', axis=0))\n",
        "report += param_section(params)\n",
        "img_dir = path.join(REPORT_DIR, 'img')\n",
        "os.makedirs(img_dir, exist_ok=True)\n",
        "report += fit_section_md(g_ref, g_popt, g_pcov, img_dir) # TODO: !!! global fit_result[3]\n",
        "\n",
        "report += sample_section_md(samplesk, g_ref, img_dir)\n",
        "\n",
        "print(REPORT_FILE_PATH)\n",
        "save_md(REPORT_FILE_PATH, report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res = bytearray(report,'utf8')\n",
        "t = crc32(res)\n",
        "crc_report = 2898421151\n",
        "if t != crc_report:\n",
        "    raise Exception('Report CRC missmatch! {} != {}'.format(t, crc_report))\n",
        "    print('\\nReport CRC  = {}\\n'.format(t))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aS7JK3DM_CE5"
      },
      "source": [
        "### Export to PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHf5agnXnzdp"
      },
      "outputs": [],
      "source": [
        "from md2pdf.core import md2pdf\n",
        "PDF_FILE_PATH = path.join(REPORT_DIR,\"{}.pdf\".format(os.path.basename(REPORT_FILE_PATH)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNCx1zronwsj"
      },
      "outputs": [],
      "source": [
        "md2pdf(PDF_FILE_PATH,\n",
        "       md_content=report,\n",
        "       md_file_path=None,\n",
        "       css_file_path=None,\n",
        "       base_url=None)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
