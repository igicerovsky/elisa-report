{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VzMkIHAq87Dq"
      },
      "source": [
        "# Intro"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Goal\n",
        "**WHAT**: Automatic report generation from Hamilton measurements.  \n",
        "**WHY**: Speed up the report generation, and avoid human errors (copying data, subjective evaluation, ....)\n",
        "\n",
        "## Tools\n",
        "Fast iteration in an agile way.  \n",
        "Generic approach - different plates setup, prameters, ... all with the same code, no changes needed.  \n",
        "\n",
        "**Python** programming language.  \n",
        "**jupyter** notebook is currently used, with some functions divided into small modules.  \n",
        "**Visual Studio Code** IDE (Integrated Development Environment).  \n",
        "**Markdown** (*.md) format for generated report (Simple, humanly redable).  \n",
        "\n",
        "## Input:\n",
        " - Worklist file path (*.xls) as used for Hamilton input.\n",
        "   - Sample name\n",
        "   - Dilution\n",
        "   - Viscosity\n",
        " - Measurement results file path (*.xls) as output from Hamilton.\n",
        " - Parameters; constants in code (file path *.json)\n",
        "   - CV (Coefficient of variation) threshold\n",
        "   - Referennce value (1.7954e+10 cp/ml)\n",
        "   - Dilutions [1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0]\n",
        "   - Decimal digits for output\n",
        "\n",
        "## Output:\n",
        "  - Report (*.md, printable to pdf)\n",
        "    - Could be manually edited\n",
        "    - Image files\n",
        "    - Result sheets\n",
        "  - Estimated size <2kB (current)\n",
        "\n",
        "## Done\n",
        "  - Invalid sample:\n",
        "    - CV >THRESHOLD\n",
        "    - Only one point\n",
        "  - Parameters file (*.scv, *.json)\n",
        "  - Multiple plates (in worklist file)\n",
        "\n",
        "## TODO:\n",
        "  - Modules\n",
        "  - Finalize the report\n",
        "  - Running modes\n",
        "    - Python script - automatic run (command line with parameters)\n",
        "    - GUI; use modules to crete an App (code remains the same, but used from GUI)\n",
        "  - Tests (unit, integration)\n",
        "  - checksum (*.sdax); put into report\n",
        "  - Extensive testing...\n",
        "  - Automatic print to *.pdf ?\n",
        "\n",
        "## Conclusion\n",
        "End to end evaluation time reduction approximately 2h -> 20min per measurement. (thx Felix)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generate report  - POC"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "VERBOSE_NOTEBOOK = False\n",
        "WARNING_DISABLE = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DScHnqGC95-6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from os import path\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_input_paths(input_dir, base_name, sample_num):\n",
        "    worklist = path.join(input_dir, base_name + 'worklist-ELISA.xls')\n",
        "    if not os.path.isfile(worklist):\n",
        "        raise Exception(\"Worklist file path is invlaid: {}\".format(worklist))\n",
        "    results =  path.join(input_dir, base_name + 'calc{}.xlsx'.format(sample_num))\n",
        "    if not os.path.isfile(results):\n",
        "        raise Exception(\"Rewsults file path is invlaid: {}\".format(results))\n",
        "    \n",
        "    report = path.join(input_dir, 'results_{}'.format(sample_num))\n",
        "    report = path.join(report, '{}report_{}.md'.format(base_name, sample_num))\n",
        "\n",
        "    params = path.join(input_dir, base_name + 'AAV9-ELISA_Parameters.csv')\n",
        "\n",
        "    return {'worklist': worklist, 'results': results, 'report': report, 'params': params}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "WORKING_DIR = './data/input/'\n",
        "BASE_NAME = '230426_GN004240-033_-_'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zV2iKp5f9-Ui"
      },
      "source": [
        "## Read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "9QyeTtP3gQN0",
        "outputId": "f07cb86c-f322-432b-abb5-f785f8efd4be"
      },
      "outputs": [],
      "source": [
        "PLATE_ID = 1 # plate id\n",
        "\n",
        "input_files = make_input_paths(WORKING_DIR, BASE_NAME, PLATE_ID)\n",
        "WORKLIST_FILE_PATH = input_files['worklist']\n",
        "RESULT_FILE_PATH = input_files['results']\n",
        "REPORT_FILE_PATH = input_files['report']\n",
        "REPORT_DIR = os.path.dirname(os.path.abspath(REPORT_FILE_PATH))\n",
        "\n",
        "params = pd.read_csv(input_files['params'], sep=';')\n",
        "params.set_index('Variable', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "xoHKHdi6pVOp",
        "outputId": "25c35044-7f6c-405a-e516-cfd8c631a2cb"
      },
      "outputs": [],
      "source": [
        "from readdata import read_concat_data\n",
        "\n",
        "m = read_concat_data(RESULT_FILE_PATH)\n",
        "display(m)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BNLvIjir8ygz"
      },
      "source": [
        "### Layouts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "EhcUq4gagUvF",
        "outputId": "419c96ca-d9f1-4c13-f3f8-ad9e23662719"
      },
      "outputs": [],
      "source": [
        "from layouthandle import read_plate_layout\n",
        "\n",
        "plate_layout = read_plate_layout('./data/plate_layout.csv')\n",
        "plate_layout_id = read_plate_layout('./data/plate_layout_ident.csv')\n",
        "plate_layout_num = read_plate_layout('./data/plate_layout_num.csv')\n",
        "plate_layout_dil_id = read_plate_layout('./data/plate_layout_dil_id.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if VERBOSE_NOTEBOOK:\n",
        "    display(plate_layout_id)\n",
        "    display(plate_layout_num)\n",
        "    display(plate_layout_dil_id)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Combine read data from XLSX with layouts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from readdata import to_multi_index\n",
        "from layouthandle import concat_data_and_layout\n",
        "\n",
        "df_all = concat_data_and_layout(m, to_multi_index(plate_layout_id, 'plate_layout_ident'))\n",
        "df_all = concat_data_and_layout(df_all, to_multi_index(plate_layout_num, 'plate_layout_num'))\n",
        "df_all = concat_data_and_layout(df_all, to_multi_index(plate_layout_dil_id, 'plate_layout_dil_id'))\n",
        "\n",
        "if VERBOSE_NOTEBOOK:\n",
        "    display(m)\n",
        "    display(df_all)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Filter data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if VERBOSE_NOTEBOOK:\n",
        "    display(df_all.loc[(df_all['plate_layout_ident']=='r')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sample import get_sample\n",
        "\n",
        "if VERBOSE_NOTEBOOK:\n",
        "    display(get_sample(df_all, 's', 1))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dilution to Concentration\n",
        "\n",
        "Define dilution dataframe. The dataframe is indexed according plate layout, index of refference dataframe corresponds to refference of the `plate_layout_dil`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: read reference value from parameters\n",
        "REF_VAL_MAX = 1.7954e+10\n",
        "DILUTIONS = [1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0]\n",
        "\n",
        "from sample import make_concentration\n",
        "reference_conc = make_concentration(REF_VAL_MAX, DILUTIONS)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check the `reference_set_conc` indexing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if VERBOSE_NOTEBOOK:\n",
        "    display(reference_conc)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fitdata\n",
        "import warnings\n",
        "from scipy.optimize import OptimizeWarning\n",
        "\n",
        "if WARNING_DISABLE:\n",
        "    warnings.simplefilter('ignore', RuntimeWarning)\n",
        "    warnings.simplefilter('ignore', OptimizeWarning)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get the fitting data from dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ref = df_all.loc[(df_all['plate_layout_ident']=='r')].copy()\n",
        "ref['plate_layout_dil'] = ref['plate_layout_dil_id'].map(reference_conc['concentration'])\n",
        "if VERBOSE_NOTEBOOK:\n",
        "    display(ref)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fit with confidence interval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CONFIDENCE_INTERVAL = 95.0 # 95% confidence interval = 100*(1-alpha)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Backfit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from image import fit_image\n",
        "from fitdata import fit_reference_auto_rm\n",
        "\n",
        "x = ref.reset_index(level=[0,1])['plate_layout_dil']\n",
        "y = ref.reset_index(level=[0,1])['OD_delta']\n",
        "fit_result = fit_reference_auto_rm(x, y, verbose=False)\n",
        "popt = fit_result[0][0]\n",
        "pcov = fit_result[0][1]\n",
        "\n",
        "fit_image(x, y, fit_result[0][0], fit_result[0][1], None, confidence='student-t', rm_index=fit_result[1])\n",
        "display(fit_result[3])\n",
        "display(fit_result[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from fitdata import backfit\n",
        "\n",
        "bf = backfit(ref, popt)\n",
        "\n",
        "od_min = bf['Optical density'].min()\n",
        "od_max = bf['Optical density'].max()\n",
        "\n",
        "od_fit_min = bf['SV to OD fit'].min()\n",
        "od_fit_max = bf['SV to OD fit'].max()\n",
        "\n",
        "sv_min = bf['Standard Value [cp/ml]'].min()\n",
        "sv_max = bf['Standard Value [cp/ml]'].max()\n",
        "\n",
        "cb_min = bf['Concentration backfit [cp/ml]'].min()\n",
        "cb_max = bf['Concentration backfit [cp/ml]'].max()\n",
        "\n",
        "if VERBOSE_NOTEBOOK:\n",
        "    display(bf)\n",
        "    print('Concentration backfit [cp/ml] range <{0}, {1}>'.format(cb_min, cb_min))\n",
        "    print('Standard Value [cp/ml] range <{0}, {1}>'.format(sv_min, sv_max))\n",
        "    print('SV to OD fit range <{0:.4f}, {1:.4f}>'.format(od_fit_min, od_fit_max))\n",
        "    print('Optical density range <{0:.4f}, {1:.4f}>'.format(od_min, od_max))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sample evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if VERBOSE_NOTEBOOK:\n",
        "    display(get_sample(df_all, 's', 1))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit the data, and apply the inverse function as a check..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sample import unique_sample_numbers\n",
        "\n",
        "samplesk = df_all.loc[(df_all['plate_layout_ident']=='s') | (df_all['plate_layout_ident']=='k') | (df_all['plate_layout_ident']=='r')]\n",
        "samplesk.loc[:, ['plate_layout_dil']] = samplesk['plate_layout_dil_id'].map(reference_conc['dilution'])\n",
        "display(samplesk)\n",
        "\n",
        "sample_nums = unique_sample_numbers(samplesk)\n",
        "display(sample_nums)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compute concentration for all `s` and `k` samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from fitdata import conc_func\n",
        "\n",
        "samplesk.loc[:, ['concentration']] = samplesk.apply(lambda x: conc_func(x['OD_delta'], x['plate_layout_dil'], *popt), axis=1)\n",
        "samplesk.loc[:, ['backfit']] = samplesk.apply(lambda x: fitdata.inv_func(x['OD_delta'], *popt), axis=1)\n",
        "\n",
        "if VERBOSE_NOTEBOOK:\n",
        "    display(samplesk)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sample masking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sample import mask_reason_fn\n",
        "from sample import mask_reason_short_fn\n",
        "\n",
        "samplesk.loc[:, ['od_mask_reason']] = samplesk.apply(lambda x: mask_reason_fn(x['OD_delta'], od_min, od_max, 'Measured OD'), axis=1)\n",
        "samplesk.loc[:, ['mask_reason']] = samplesk.apply(lambda x: mask_reason_short_fn(x['backfit'], cb_min, cb_max, x['plate_layout_dil'], ''), axis=1)\n",
        "\n",
        "if VERBOSE_NOTEBOOK:\n",
        "    display(samplesk)\n",
        "    print('Optical density range = <{0:.4f}, {1:.4f}>'.format(od_min, od_max))\n",
        "    print('Backfit range = <{0:.4e}, {1:.4e}>'.format(Decimal(sv_min), sv_max))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.stats import variation\n",
        "import constants as cnt\n",
        "from sample import process_sample\n",
        "from sample import sample_check\n",
        "\n",
        "\n",
        "# def process_sample(samples, stype, sample_num):\n",
        "#     sample = get_sample(samples, stype, sample_num)\n",
        "#     smp_t = sample[sample.mask_reason.isna()]\n",
        "#     cv = np.nan\n",
        "#     mean = np.nan\n",
        "#     if len(smp_t['concentration']) > 1:\n",
        "#         cv = variation(smp_t['concentration'], ddof=1)\n",
        "#         mean = np.mean(smp_t['concentration'])\n",
        "#     elif len(smp_t['concentration']) == 1:\n",
        "#         mean = numpy.mean(smp_t['concentration'])\n",
        "\n",
        "#     return sample, cv, mean\n",
        "\n",
        "\n",
        "# def sample_check(samples, stype, sample_num, cv_thresh=CV_THRESHOLD,\n",
        "#                  min_valid_pts=MIN_VALID_SAMPLE_POINTS):\n",
        "#     s = process_sample(samples, stype, sample_num)\n",
        "#     valid = True\n",
        "#     note = ''\n",
        "#     if s[1] > cv_thresh:\n",
        "#         note = 'CV > {}; '.format(cv_thresh)\n",
        "#         valid = False\n",
        "#     smp = s[0]\n",
        "#     valid_pts = smp['mask_reason'].isna().sum()\n",
        "#     if valid_pts < min_valid_pts:\n",
        "#         note += 'Not enough valid sample points. Required {}, available {};'.format(min_valid_pts, valid_pts)\n",
        "#         valid = False\n",
        "#     elif valid_pts != len(smp['mask_reason']):\n",
        "#         note += 'Reduced number of sample points. Measured {}, valid {};'.format(len(smp['mask_reason']), valid_pts)\n",
        "#         valid &= True\n",
        "\n",
        "#     note_cols = smp[~smp['mask_reason'].isna()]\n",
        "#     if len(note_cols)!= 0:\n",
        "#         if (note_cols['mask_reason'] == note_cols['mask_reason'][0]).all():\n",
        "#             note += note_cols['mask_reason'][0] + ';' + note_cols['od_mask_reason'][0]\n",
        "#         # else:\n",
        "#         #     note += note_cols['mask_reason'].str.cat(sep=', ')\n",
        "\n",
        "#     return {'sample':smp, 'cv':s[1], 'mean':s[2], 'note':note, 'type':stype, 'num':sample_num, 'valid':valid, 'valid_pts': valid_pts}\n",
        "\n",
        "\n",
        "def print_sample(number, stype, sample, cv, mean):\n",
        "    display(sample[['OD_delta', 'plate_layout_dil', 'concentration', 'backfit', 'mask_reason']])\n",
        "    print(\"{1} '{2}' {0}\".format(number, SAMPLE_TYPES[stype], stype))\n",
        "    print(\"CV = {:2.3} [%]\".format(100 * cv))\n",
        "    print(\"mean = {:.4} [cp/ml]\".format(mean))\n",
        "\n",
        "\n",
        "def print_sample_dc(sample_dict):\n",
        "    display(sample_dict['sample'][['OD_delta', 'plate_layout_dil', 'concentration', 'backfit', 'mask_reason']])\n",
        "    print(\"{1} '{2}' {0}\".format(sample_dict['num'], cnt.SAMPLE_TYPES[sample_dict['type']], sample_dict['type']))\n",
        "    print(\"CV = {:2.3} [%]\".format(100 * sample_dict['cv']))\n",
        "    print(\"mean = {:.4} [cp/ml]\".format(sample_dict['mean']))\n",
        "    print(\"valid = {}\".format(sample_dict['valid']))\n",
        "    print(\"note: {}\".format(sample_dict['note']))\n",
        "\n",
        "sc = sample_check(samplesk, 'k', 1)\n",
        "sample_results = pd.DataFrame(columns=['id', 'cv', 'cp_mean', 'Note', 'Valid'])\n",
        "for i in [14]:#sample_nums: [5, 6, 9]\n",
        "    stype = 's'\n",
        "    # s = process_sample(samplesk, 's', i)\n",
        "    # print_sample(i, 's', *s)\n",
        "    sc = sample_check(samplesk, 's', i)\n",
        "    print_sample_dc(sc)\n",
        "    sample_results.loc[len(sample_results)] = ['sample {:02d}'.format(i),\n",
        "                                               sc['cv'], sc['mean'], sc['note'], sc['valid']]\n",
        "    if i == 3: break;\n",
        "\n",
        "display(sample_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from enum import Enum\n",
        "from decimal import Decimal\n",
        "\n",
        "class SampleInfo(str, Enum):\n",
        "    NAN_LOW = 'NaN below reference'\n",
        "    NAN_HIGH = 'NaN above reference'\n",
        "    LOW = 'value below reference'\n",
        "    HIGH = 'value above reference'\n",
        "    CV = 'CV above threshold'\n",
        "    VALID_PTS = 'few valid points'\n",
        "\n",
        "\n",
        "def sampleinfo_to_str(info, multiplier=1.0):\n",
        "    if info is None:\n",
        "        return None\n",
        "\n",
        "    if not info:\n",
        "        return None;\n",
        "    \n",
        "    if info['enum'] == SampleInfo.CV:\n",
        "        return 'CV>{:.1f}%({:.1f}%)'.format(CV_THRESHOLD * 100, float(info['value']) * 100.0)\n",
        "\n",
        "    if info['enum'] == SampleInfo.VALID_PTS:\n",
        "        return '{} valid point'.format(info['value'])\n",
        "\n",
        "    return '{}{:.4e}'.format(info['sign'], float(info['value']) * multiplier)\n",
        "\n",
        "\n",
        "def sample_info(samples, stype, sample_num, verbose=False):\n",
        "    s = get_sample(samples, stype, sample_num)\n",
        "    sc = sample_check(samples, stype, sample_num)\n",
        "    if verbose:\n",
        "        display(s)\n",
        "        # display(k)\n",
        "        print('OD=[{}, {}]'.format(od_min, od_max))\n",
        "        print('OD_fit=[{:.3}, {:.3}]'.format(Decimal(od_fit_min), Decimal(od_fit_max)))\n",
        "        print('SV=[{:.3e}, {:.3e}]'.format(Decimal(sv_min), Decimal(sv_max)))\n",
        "        print('CB=[{}, {}]'.format(cb_min, cb_max))\n",
        "    above_ref_od_max = s['OD_delta'] > od_fit_max\n",
        "    below_ref_od_min = s['OD_delta'] < od_fit_min\n",
        "    msgdc = {}\n",
        "    if s['backfit'].isna().all():\n",
        "        if above_ref_od_max.all():\n",
        "            msgdc = {'sign': '>', 'value': Decimal(sv_max), 'enum': SampleInfo.NAN_HIGH}\n",
        "        if below_ref_od_min.all():\n",
        "            msgdc = {'sign': '<', 'value': Decimal(sv_min), 'enum': SampleInfo.NAN_LOW}\n",
        "    elif sc['cv'] > cnt.CV_THRESHOLD:\n",
        "        msgdc = {'sign': '>{:.2f}'.format(cnt.CV_THRESHOLD), 'value': sc['cv'], 'enum': SampleInfo.CV}\n",
        "    elif not s['mask_reason'].isna().all():\n",
        "        t = s[['OD_delta', 'plate_layout_dil', 'concentration', 'backfit']]\n",
        "        t_not_na = t[~t['backfit'].isna()]\n",
        "        \n",
        "        if t_not_na['OD_delta'].max() < od_fit_min:\n",
        "            t_below_ref = t_not_na[below_ref_od_min]\n",
        "            # msgdc = {'sign': '<', 'value': t_below_ref['concentration'].max(), 'enum': SampleInfo.LOW}\n",
        "            msgdc = {'sign': '<', 'value': Decimal(sv_min * sc['sample']['plate_layout_dil'].min()), 'enum': SampleInfo.LOW}\n",
        "        elif t_not_na['OD_delta'].min() > od_fit_max:\n",
        "            t_above_ref = t_not_na[above_ref_od_max]\n",
        "            # print('*** {} *  {} = {}'.format(sv_max, sc['sample']['plate_layout_dil'].max(), sv_max * sc['sample']['plate_layout_dil'].max()))\n",
        "            msgdc = {'sign': '>', 'value': Decimal(sv_max * sc['sample']['plate_layout_dil'].max()), 'enum': SampleInfo.HIGH}\n",
        "    \n",
        "    if sc['valid_pts'] < cnt.MIN_VALID_SAMPLE_POINTS and sc['valid_pts'] != 0:\n",
        "        msgdc = {'sign': '', 'value': sc['valid_pts'], 'enum': SampleInfo.VALID_PTS}\n",
        "\n",
        "    del sc['sample']\n",
        "    del sc['note']\n",
        "    sc['info'] = msgdc\n",
        "    \n",
        "    return sc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "si = sample_info(samplesk, 's', 6)\n",
        "si"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_results = pd.DataFrame(columns=['id', 'CV [%]', 'Reader Data [cp/ml]', 'Note', 'Valid', 'info'])\n",
        "knum = 1\n",
        "s = sample_check(samplesk, 'k', knum)\n",
        "si = sample_info(samplesk, 'k', knum)\n",
        "display(si)\n",
        "sample_results.loc[len(sample_results)] = ['control {:02d}'.format(knum), s['cv'], s['mean'], s['note'], s['valid'], si]\n",
        "\n",
        "rnum = 1\n",
        "s = sample_check(samplesk, 'r', rnum)\n",
        "si = sample_info(samplesk, 'r', knum)\n",
        "sample_results.loc[len(sample_results)] = ['reference {:02d}'.format(knum), s['cv'], s['mean'], s['note'], s['valid'], si]\n",
        "\n",
        "for i in sample_nums:\n",
        "    stype = 's'\n",
        "    s = sample_check(samplesk, 's', i)\n",
        "    si = sample_info(samplesk, 's', i)\n",
        "    sample_results.loc[len(sample_results)] = ['sample {:02d}'.format(i), s['cv'], s['mean'], s['note'], s['valid'], si]\n",
        "\n",
        "sample_results.set_index(sample_results['id'], inplace=True)\n",
        "sample_results = sample_results.drop('id', axis=1)\n",
        "sl = sample_results\n",
        "display(sl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "si = sample_info(samplesk, 's', 1, True)\n",
        "display(si)\n",
        "sampleinfo_to_str(si['info'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot sample with referene curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mask_index(df):\n",
        "    b = df.reset_index(level=[0,1])\n",
        "    b = b[b['mask_reason'].notna()]\n",
        "\n",
        "    return b.index\n",
        "\n",
        "\n",
        "def na_index(df):\n",
        "    b = df.reset_index(level=[0,1])\n",
        "    b = b[b['backfit'].isna()]\n",
        "    \n",
        "    return b.index\n",
        "\n",
        "\n",
        "def sample_img(samples, sample_type, sample_num, img_file=None, show=True, verbose=False):\n",
        "    sd = sample_check(samplesk, sample_type, sample_num)\n",
        "    if verbose:\n",
        "        print(sample_type, sample_num)\n",
        "        display(sd['sample'])\n",
        "\n",
        "    mask_idx = mask_index(sd['sample'])\n",
        "    x = ref.reset_index(level=[0,1])['plate_layout_dil']\n",
        "    y = ref.reset_index(level=[0,1])['OD_delta']\n",
        "    fit_result = fit_reference_auto_rm(x, y, verbose=verbose)\n",
        "    # compute original concenmtration \n",
        "    sd['sample'].loc[:, ['conc_plot']] = sd['sample'].apply(lambda x: x['concentration'] / x['plate_layout_dil'], axis=1)\n",
        "    sx = sd['sample'].reset_index(level=[0,1])['conc_plot']\n",
        "    sy = sd['sample'].reset_index(level=[0,1])['OD_delta']\n",
        "    fit_image(x, y, fit_result[0][0], fit_result[0][1], img_file, confidence='student-t',\n",
        "              rm_index=fit_result[1], mask_index=mask_idx,\n",
        "              sx=sx, sy=sy, sna_idx=na_index(sd['sample']), show=show, valid_sample=sd['valid'], interval_ratio=1.0)\n",
        "    # display(na_index(sd['sample']))\n",
        "    \n",
        "sample_img(samplesk, 's', 6)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Worklist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_worklist(wl):\n",
        "    valid_plates = []\n",
        "    for i in range(1, 4):\n",
        "        invalid_sample = wl['SampleID_{}'.format(i)].isnull().values.any()\n",
        "        if not invalid_sample: valid_plates.append(i)\n",
        "    return valid_plates\n",
        "\n",
        "\n",
        "def read_worklist(worklist_file):\n",
        "    wl = pd.read_excel(worklist_file)\n",
        "    wl.set_index([['control 01', 'reference 01', 'blank', 'sample 01', 'sample 02', 'sample 03',\n",
        "        'sample 04', 'sample 05', 'sample 06', 'sample 07', 'sample 08', 'sample 09', 'sample 10',\n",
        "        'sample 11', 'sample 12', 'sample 13', 'sample 14', 'sample 15', 'sample 16', 'sample 17',\n",
        "        'sample 18', 'sample 19', 'sample 20', 'sample 21']], inplace=True)\n",
        "    check_worklist(wl)\n",
        "    wl.drop('blank', axis=0, inplace=True)\n",
        "    wl.index.name = 'Sample type'\n",
        "\n",
        "    return wl\n",
        "\n",
        "\n",
        "def worklist_sample(wl, plate_id):\n",
        "    invalid_sample = wl['SampleID_{}'.format(plate_id)].isnull().values.any()\n",
        "    if invalid_sample:\n",
        "        return None, None\n",
        "    \n",
        "    cols_id =['SampleID', 'Dilution', 'Viscosity']\n",
        "    cols = [x + '_' + str(plate_id) for x in cols_id]\n",
        "    cols_dict = {x : y for x,y in zip(cols_id, cols)}\n",
        "\n",
        "    return wl[cols], cols_dict\n",
        "\n",
        "\n",
        "wl_raw = read_worklist(WORKLIST_FILE_PATH)\n",
        "valid_plates = check_worklist(wl_raw)\n",
        "wl, wl_cols_dict = worklist_sample(wl_raw, PLATE_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def final_sample_info(all_info, pre_dilution, verbose=False):\n",
        "    info = all_info['info']\n",
        "    if not all_info: raise Exception(\"Invalid sample info!\")\n",
        "    if not info:\n",
        "        return '', True\n",
        "    \n",
        "    msg = ''\n",
        "    valid_ex = False\n",
        "    if info['enum'] == SampleInfo.NAN_HIGH:\n",
        "        msg = '>{:.4e}'.format(info['value'] * pre_dilution)\n",
        "    elif info['enum'] == SampleInfo.NAN_LOW:\n",
        "        valid_ex = True\n",
        "        msg = '<{:.4e}'.format(info['value'] * pre_dilution)\n",
        "    elif info['enum'] == SampleInfo.HIGH:\n",
        "        msg = '>{:.4e}'.format(info['value'] * pre_dilution)\n",
        "    elif info['enum'] == SampleInfo.LOW:\n",
        "        msg = '<{:.4e}'.format(info['value'] * pre_dilution)\n",
        "        valid_ex = True\n",
        "    elif info['enum'] == SampleInfo.VALID_PTS:\n",
        "        msg = '{} valid point'.format(all_info['valid_pts'])\n",
        "    elif info['enum'] == SampleInfo.CV:\n",
        "        msg = 'CV>{:.2f}%({:.2f}%)'.format(CV_THRESHOLD * 100.0, info['value'] * 100.0)\n",
        "    else:\n",
        "        msg = ''\n",
        "        valid_ex = True\n",
        "\n",
        "    return msg, valid_ex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: nasty, using globals!!!\n",
        "def make_final():\n",
        "    final = pd.concat([wl, sl], axis=1)\n",
        "    cd = wl_cols_dict\n",
        "    final.loc[:, ['Result [cp/ml]']] = final.apply(lambda x: x['Reader Data [cp/ml]'] * x[cd['Dilution']], axis=1)\n",
        "    final.loc[:, ['CV [%]']] = final.apply(lambda x: x['CV [%]'] * 100, axis=1)\n",
        "    # reorder columns\n",
        "    final = final.reindex([cd['SampleID'], cd['Dilution'], cd['Viscosity'], 'Reader Data [cp/ml]', 'Result [cp/ml]', 'CV [%]', 'Valid', 'info'], axis=1)\n",
        "    final.rename(columns={cd['SampleID']: 'Sample Name', cd['Dilution']: 'Pre-dilution'}, inplace=True)\n",
        "    final.drop('Viscosity_{}'.format(PLATE_ID), axis=1, inplace=True)\n",
        "    final.index.name = 'Sample type'\n",
        "    final.loc[:, ['info_ex']] = final.apply(lambda x: final_sample_info(x['info'], x['Pre-dilution'])[0], axis=1)\n",
        "    final.loc[:, ['valid_ex']] = final.apply(lambda x: final_sample_info(x['info'], x['Pre-dilution'])[1], axis=1)\n",
        "    return final\n",
        "\n",
        "# final = make_final()\n",
        "# final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final = make_final()\n",
        "final"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pbq4Hm3A-DPa"
      },
      "source": [
        "## Plate Layout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = plate_layout_num.replace({'b':-99}).astype(float)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "YHCaH9mqvaPo",
        "outputId": "dbd268eb-cf2b-4789-a9cd-ba72817b9821"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "vals = np.around(df.values, 2)\n",
        "norm = plt.Normalize(vals.min()-1, vals.max()+1)\n",
        "colours = plt.cm.hot(norm(vals))\n",
        "\n",
        "fig = plt.figure(figsize=(8,6))\n",
        "ax = fig.add_subplot(111, frameon=False, xticks=[], yticks=[])\n",
        "\n",
        "the_table=plt.table(cellText=vals, rowLabels=df.index, colLabels=df.columns,\n",
        "                    loc='center', cellColours=colours)\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gZvoKky5-zeC"
      },
      "source": [
        "## Report  \n",
        "We build a report here..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fit Reference Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from fitdata import fit_sheet\n",
        "\n",
        "def fit_section_md(df_ref, popt, pcov, out_dir):\n",
        "    x = df_ref.reset_index(level=[0,1])['plate_layout_dil']\n",
        "    y = df_ref.reset_index(level=[0,1])['OD_delta']\n",
        "    fit_result = fit_reference_auto_rm(x, y)\n",
        "    result_img = path.join(out_dir, 'fit.svg')\n",
        "    fit_image(x, y, fit_result[0][0], fit_result[0][1], result_img, confidence='student-t', rm_index=fit_result[1])\n",
        " \n",
        "    n = len(x) - len(fit_result[1])\n",
        "    df_fit = fit_sheet(popt, pcov, n)\n",
        "    display(df_fit)\n",
        "\n",
        "    md = '## Reference Curve Fit\\n\\n'\n",
        "    md += '$\\LARGE y = {d + {a - d \\over {1 + ({ x \\over c })^b}} }$  \\n\\n'\n",
        "    md += '![\"alt text\"](./img/fit.svg)'\n",
        "\n",
        "    md += '\\n\\n'\n",
        "    md += 'Verbose fitting progress, metric is R-squared:\\n\\n'\n",
        "    md += fit_result[3].to_markdown() + '\\n\\n'\n",
        "\n",
        "    md += 'Fit parameters\\n\\n'\n",
        "    md += df_fit.to_markdown(index=False) + '\\n\\n'\n",
        "    md += 'Backfit...'\n",
        "    fit_result = fit_reference_auto_rm(x, y)\n",
        "    df_backfit = backfit(df_ref, fit_result[0][0])\n",
        "    md += '\\n\\n' + df_backfit.to_markdown() + '\\n\\n'\n",
        "\n",
        "    # cv = variation(df_backfit['concentration'], ddof=1)\n",
        "\n",
        "    return md\n",
        "\n",
        "# fit_section_md(ref, popt, pcov, REPORT_DIR)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mITvKNH5-4fX"
      },
      "source": [
        "### Sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRtUZG23mF2m"
      },
      "outputs": [],
      "source": [
        "def sample_to_md(dc):\n",
        "    s_view = dc['sample'][['OD_delta', 'plate_layout_dil', 'concentration', 'mask_reason']]\n",
        "    md = \"### Sample: {0} '{1}' {2}\\n\\n\".format(SAMPLE_TYPES[dc['type']], dc['type'], dc['num'])\n",
        "    md += s_view.to_markdown()\n",
        "    md += '\\n\\n'\n",
        "    md += \"CV = {:2.3} [%]  \\n\".format(100 * dc['cv'])\n",
        "    md += \"mean = {:.4} [cp/ml]  \\n\".format(dc['mean'])\n",
        "    md += \"valid = {}  \\n\".format(dc['valid'])\n",
        "    if dc['note']:\n",
        "         md += \"note: {}  \".format(dc['note'])\n",
        "\n",
        "    return md\n",
        "\n",
        "def sample_section_md(samples, img_dir):\n",
        "    md = '## Sample evaluation\\n\\n' \n",
        "    k = sample_check(samples, 'k', 1)\n",
        "    md += sample_to_md(k)\n",
        "    sfile = 'control_{0:02d}.svg'.format(1)\n",
        "    img_file = path.join(img_dir, sfile)\n",
        "    sample_img(samples, 'k', 1, img_file, show=False)\n",
        "    md += '![\"alt text\"](./img/{})\\n\\n'.format(sfile)\n",
        "    sample_n = samples['plate_layout_num'].astype(int).unique()\n",
        "    sample_n.sort()\n",
        "    for i in sample_n:\n",
        "        stype = 's'\n",
        "        s = sample_check(samples, stype, i)\n",
        "        md += sample_to_md(s)\n",
        "        # sample info\n",
        "        si = sample_info(samples, stype, i, verbose=False)\n",
        "        si_str = sampleinfo_to_str(si['info'])\n",
        "        if si_str:\n",
        "            md += '\\n'\n",
        "            md += 'info: ' + si_str + '  '\n",
        "        md += '\\n'\n",
        "        sfile = 'sample_{0:02d}.svg'.format(i)\n",
        "        img_file = path.join(img_dir, sfile)\n",
        "        sample_img(samples, stype, i, img_file=img_file, show=False, verbose=False)\n",
        "        md += '![{0}](./img/{0})\\n\\n'.format(sfile)\n",
        "    return md\n",
        "\n",
        "def save_md(file_path, md_txt):\n",
        "    try:\n",
        "        with open(file_path, 'w') as fl:\n",
        "            fl.write(md_txt)\n",
        "    except Exception as e:\n",
        "        print('Error: ' + str(e))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_result = make_final()\n",
        "\n",
        "def format_resluts_val(x):\n",
        "    res = ''\n",
        "    if math.isnan(x['Result [cp/ml]']):\n",
        "        res = x['Comment']\n",
        "    else:\n",
        "        res = '{:.4e}'.format(x['Result [cp/ml]'])\n",
        "    if x['valid_ex']:\n",
        "        res = '**{}**'.format(res)\n",
        "    else:\n",
        "        res = '( {} )*'.format(res)\n",
        "    \n",
        "    return res\n",
        "\n",
        "def format_results(df):\n",
        "    df.loc[:, ['Comment']] = df.apply(lambda x: final_sample_info(x['info'], x['Pre-dilution'])[0], axis=1)\n",
        "    df.loc[:, ['CV [%]']] = df.apply(lambda x:'{:.2f}'.format(x['CV [%]']), axis=1)\n",
        "    # df.loc[:, ['Result [cp/ml]']] = df.apply(lambda x: x['Comment'] if math.isnan(x['Result [cp/ml]']) else '{:.4e}'.format(x['Result [cp/ml]']), axis=1)\n",
        "    # display(df)\n",
        "    df.loc[:, ['Result [cp/ml]']] = df.apply(lambda x: format_resluts_val(x), axis=1)\n",
        "    df.drop(['info', 'Valid', 'Reader Data [cp/ml]', 'info_ex', 'valid_ex'], axis=1, inplace=True)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# format_results(final_result)\n",
        "# final_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def result_section(df):\n",
        "    md = '## Analysis Results\\n\\n'\n",
        "\n",
        "    md += format_results(df).to_markdown()\n",
        "    md += '\\n\\n'\n",
        "    \n",
        "    return md\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Header"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def header_section(date, id, plate_id, msg):\n",
        "    md =  '## Header\\n\\n'\n",
        "\n",
        "    md += 'Date: {}\\n\\n'.format(date)\n",
        "    md += 'Identification: {}\\n\\n'.format(id)\n",
        "    md += 'Plate: {}\\n\\n'.format(plate_id)\n",
        "    md += 'Comment: {}\\n\\n'.format(msg)\n",
        "\n",
        "    return md;"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def param_section(df_params):\n",
        "    md =  '## Parameters\\n\\n'\n",
        "\n",
        "    md += 'Parameters:\\n\\n' + df_params.to_markdown() + '\\n\\n'\n",
        "\n",
        "    return md;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_result"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Report Assembly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "report = '''\n",
        "# Automatically Generated Markdown report\n",
        "\n",
        "This a PoC for automatic report generation...  \n",
        "\n",
        "'''\n",
        "\n",
        "report += header_section('05 May 2023', 'GN004240-033', PLATE_ID, ':)')\n",
        "report += result_section(final_result.drop('reference 01', axis=0))\n",
        "report += param_section(params)\n",
        "img_dir = path.join(REPORT_DIR, 'img')\n",
        "os.makedirs(img_dir, exist_ok=True)\n",
        "report += fit_section_md(ref, popt, pcov, img_dir) # TODO: !!! global fit_result[3]\n",
        "\n",
        "report += sample_section_md(samplesk, img_dir)\n",
        "\n",
        "print(REPORT_FILE_PATH)\n",
        "save_md(REPORT_FILE_PATH, report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from Markdown2docx import Markdown2docx\n",
        "# report_path_noext = os.path.abspath(os.path.splitext(REPORT_FILE_PATH)[0])\n",
        "# print(report_path_noext)\n",
        "# project = Markdown2docx(report_path_noext)\n",
        "# # project = Markdown2docx('data/input/results_2/aaa')\n",
        "# project.eat_soup()\n",
        "# project.save()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aS7JK3DM_CE5"
      },
      "source": [
        "### Export to PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHf5agnXnzdp"
      },
      "outputs": [],
      "source": [
        "from md2pdf.core import md2pdf\n",
        "PDF_FILE_PATH = path.join(REPORT_DIR,\"{}.pdf\".format(os.path.basename(REPORT_FILE_PATH)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNCx1zronwsj"
      },
      "outputs": [],
      "source": [
        "md2pdf(PDF_FILE_PATH,\n",
        "       md_content=report,\n",
        "       md_file_path=None,\n",
        "       css_file_path=None,\n",
        "       base_url=None)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
